---
layout: mypost
title: bert、ner资料
categories: [nlp]
---

# bert资料

整理一些bert和ner的资料。



## 参考资料
>bert + bilstm + crf
>> [基于BERT预训练的中文命名实体识别TensorFlow实现](https://blog.csdn.net/macanv/article/details/85684284)<br>
>> [动手实践bert+BiLstm+crf](https://blog.csdn.net/liuzonghao88/article/details/93748359)<br>
>> []()<br>

>ner
>> [【NER】对命名实体识别(槽位填充)的一些认识](http://www.manongjc.com/detail/8-vmvtsmzsqqjyfvn.html)<br>
>> [kugwzk's space](http://kugwzk.info/index.php/archives/tag/ner)<br>
>> [基于Bert-NER构建特定领域的中文信息抽取框架（上）](https://www.freebuf.com/column/209195.html)<br>
>> [How do I train an NER in BERT?](https://www.quora.com/How-do-I-train-an-NER-in-BERT)<br>
>> [BERT-NER](https://modelzoo.co/model/bert-ner)<br>
>> [Named Entity Recognition With Bert](https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/)<br>
>> [NERsuite
A Named Entity Recognition toolkit](http://nersuite.nlplab.org/index.html)<br>
>> [【15個掲載】固有表現抽出に使えるデータセットまとめ](https://lionbridge.ai/ja/datasets/15-free-datasets-and-corpora-for-named-entity-recognition-ner/)<br>
>> [rondhuit](https://www.rondhuit.com/)<br>


>bert日本語
>> [BERT日本語Pretrainedモデル @黒橋-河原研究室](http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT%E6%97%A5%E6%9C%AC%E8%AA%9EPretrained%E3%83%A2%E3%83%87%E3%83%AB)<br>
> [BERT with SentencePiece を日本語 Wikipedia で学習してモデル byyoheikikuta](https://yoheikikuta.github.io/bert-japanese/)<br>
>> [BERT導入手順おさらい個人メモ](https://qiita.com/takahashi_yukou/items/b81319b8ef6cee13cb1b)<br>
>> [PYTORCHでBERTの日本語学習済みモデルを利用する - 文章埋め込み編](https://yag-ays.github.io/project/pytorch_bert_japanese/)<br>
>> [BERTによる文書分類](https://orizuru.io/blog/machine-learning/bert/)<br>
>> [BERTの日本語事前学習済みモデルでテキスト埋め込みをやってみる](https://dev.classmethod.jp/machine-learning/bert-text-embedding/)<br>
>> [自然言語処理で注目のBERT ~取り敢えず動かしてみる編~](https://qiita.com/neonsk/items/27424d6122e00fe632b0)<br>
>> [pytorch-transformersを触ってみる②](http://kento1109.hatenablog.com/entry/2019/08/21/155810)<br>
>> [BERT日本語Pretrainedモデルを利用した日本語文章の尤度](https://qiita.com/ohchun/items/e234ea5df3c16316813e)<br>
>> [BERT(日本語Pretrainedモデル) as Language Model](https://github.com/ohchun/bert-as-language-model)<br>
> []()<br>

>工具
>> [词向量可视化工具Embedding Projector](https://ai.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html?spm=5176.100239.0.0.klIQ9e)<br>
>> [Tensorboard教程：高维向量可视化](https://blog.csdn.net/u013555719/article/details/81099860)<br>
>> [医療言語処理グループ](http://sociocom.jp/~sociocom/mednlp/)<br>
